"general":
  "id": "test_dyna_model_learning"
  "seed": 0
  "repeat": 1
  "is_tensorboardX": false
  "sumo_home": "/home/ncarrara/sumo_binaries/bin"
  "workspace": "tmp"
  "logging":
    "version": 1
    "disable_existing_loggers": false
    "formatters":
      "standard":
        "format": "[%(name)s] %(levelname)s - %(message)s"
    "handlers":
      "default":
        "level": "WARNING"
        "formatter": "standard"
        "class": "logging.StreamHandler"
    "loggers":
      "":
        "handlers": ["default"]
        "level": "WARNING"
        "propagate": false
      "some.logger.you.want.to.enable.in.the.code":
        "handlers": ["default"]
        "level": "ERROR"
        "propagate": false

"envs_collection": "cp_length"

"transfer":
  "baselines":

    "dyna_model_learning":
      "baseline": "dyna_model_learning"
      "eval_interval": 10 # 1000 #100
      "log_interval": 2
      "plot_interval": 50
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.01 #0.00025
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 10
      "gamma": 0.9
      "num_real_steps": 2000
      "planning_init_replay_buffer_max_length": 10
      "fake_steps_replay_buffer_max_length": 1000
      "update_model_interval": 1

  "target_gan_config":
    "D_n_updates": 1
    "G_n_updates": 1
    "D_optimizer":
      "type": "adam"
      "params":
        "learning_rate": 0.0002 #2e-4
        "beta_1": 0.5
    "G_optimizer":
      "type": "adam"
      "params":
        "learning_rate": 0.0002 #2e-4
        "beta_1": 0.5
    "use_bce_tf_function": False
    "type": "classic" # "wasserstein"
    "z_size": 1 #5
    "D_hidden_layers": [ 512, 256]
    "G_hidden_layers": [ 512, 256]
    "D_activation": "tanh"
    "G_activation": "tanh"


  "stop_mean_return": [5,200]
  "nb_runs": 1
  "use_tf_agent": False # False
  "eps_start": 0.5 # 0.5 1.0
  "minibatch_size": 64
  "num_eval_episodes": 50
  # INTERVALS #
  "training_interval": 1
  "log_target_model_performance_interval": 10
  "update_accuracy_interval": 1
  "check_stop_transfer_interval": 1
  "use_true_done_to_stop_prediction": True
  "replay_buffer_max_length": 100000

  "shape": [2,100]
  "action_selection_for_model_prediction": "greedy" #"random" #"greedy" # "random" # greedy

"cross_comparaison":
  "nb_samples": 2000
  "nb_episodes": 100

"create_datasets":
  "onehot_action": True
  "n_episodes": 5000

"gan_config":
  "data_size_by_source_env": 5000
  "batch_size": "max"
  "lambda_penalize_high_entropy": null #0.
  "sum_fake_and_real_for_entropy": null
  "stop":
    "max_epochs": 20000 #1500
    "testing_loss_treshold": 0.005
  "lambda_": 0
  "gan_dynamics": true
  "gan_reward": true
  "D_n_updates": 1
  "G_n_updates": 1
  "D_optimizer":
    "type": "adam"
    "params":
      "learning_rate": 0.0002 #2e-4
      "beta_1": 0.5
  #    "type": "rms"
  #     "params":
  #       "learning_rate": 0..001 #2e-4
  #       "beta_1": 0.5
  "G_optimizer":
    "type": "adam"
    "params":
      "learning_rate": 0.0002 #2e-4
      "beta_1": 0.5
  #    "type": "rms"
  #    "params":
  #      "learning_rate": 0..001 #2e-4
  #      "beta_1": 0.5
  "use_bce_tf_function": False
  "type": "super_gan" # "wasserstein"
  "factorize_fake_output": True
  #  "lipchitz_method": "clipping",
  "z_size": 1 #5
  "D_hidden_layers": [ 512, 256]
  "G_hidden_layers": [ 512, 256]
  "D_activation": "tanh"
  "G_activation": "tanh"
  "negative_sampling":
    "grid_search":
      - null

