"general":
  "id": "main_fast"
  "seed": 0
  "repeat": 1
  "is_tensorboardX": false
  "sumo_home": "/home/ncarrara/sumo_binaries/bin"
  "workspace": "tmp"
  "logging":
    "version": 1
    "disable_existing_loggers": false
    "formatters":
      "standard":
        "format": "[%(name)s] %(levelname)s - %(message)s"
    "handlers":
      "default":
        "level": "WARNING"
        "formatter": "standard"
        "class": "logging.StreamHandler"
    "loggers":
      "":
        "handlers": ["default"]
        "level": "WARNING"
        "propagate": false
      "some.logger.you.want.to.enable.in.the.code":
        "handlers": ["default"]
        "level": "ERROR"
        "propagate": false

"envs_collection": "fast"
"onehot_action": True

"jobs":
  - "create_datasets"
  - "learn_gans"
  - "cross_comparaison"
  - "transfer"
  - "print_transfer_results"



"transfer":
  "baselines":

    "dyna_imperfect":
      "gan_baseline": "one_gan_by_env"
      "baseline": "dyna_pretrained"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        ##    "name": "rmsprop"
        #    "params": {}
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "dyna_rdm":
      "gan_baseline": "one_gan_by_env"
      "baseline": "dyna_rdm"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        ##    "name": "rmsprop"
        #    "params": {}
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "dyna_agglo":
      "gan_baseline": "hello_agglo_gan"
      "baseline": "dyna_agglo"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        ##    "name": "rmsprop"
        #    "params": {}
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "dyna_model_learning":
      "baseline": "dyna_model_learning"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "solution_3":
      "gan_baseline": "hello_super_gan"
      "baseline": "solution_3"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "dyna_perfect":
      "baseline": "dyna_perfect"
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 3
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "lambda_decay": 0.00025
      "optimizer":
        ##    "name": "rmsprop"
        #    "params": {}
        "name": "adam"
        "params":
          "lr": 0.001
      "update_network_frequency": 1
      "gamma": 0.99
      "num_real_steps": 10

    "dqn":
      "baseline": "dqn"
      "eval_interval": 10 # 1000 #100
      "log_interval": 2
      "plot_interval": 10
      "initial_collect_steps": 0
      "offset_step_collection": 0
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "gamma": 0.99 # 0.9
      "update_network_frequency": 1 # 100 #TODO 100
      "lambda_decay": 0.00025
      "num_real_steps": 20

    "dqn_extra_updates_bootstrapped":
      "baseline": "dqn_extra_updates"
      "lambda_decay": 0.01 # must explore a bit more "non random" samples since most all init_step are randomize
      "eval_interval": 1 # 1000 #100
      "log_interval": 2
      "plot_interval": 2
      "initial_collect_steps": 3 #250
      "offset_step_collection": 3
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "gamma": 0.99 # 0.99 loss diverges
      "update_network_frequency": 1 # 100
      "num_real_steps": 10

    "dqn_extra_updates":
      "baseline": "dqn_extra_updates"
      "lambda_decay": 0.01 # must explore a bit more "non random" samples since most all init_step are randomize
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 2
      "initial_collect_steps": 0 #250
      "offset_step_collection": 0
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "gamma": 0.99 # 0.99 loss diverges
      "update_network_frequency": 10 # 100
      "num_real_steps": 10

    "dqn_extra_steps":
      "baseline": "dqn_extra_steps"
      "lambda_decay": 0.01 # must explore a bit more "non random" samples since most all init_step are randomize
      "eval_interval": 2 # 1000 #100
      "log_interval": 1
      "plot_interval": 2
      "initial_collect_steps": 0 #250
      "offset_step_collection": 0
      "optimizer":
        "name": "adam"
        "params":
          "lr": 0.001
      "gamma": 0.99 # 0.99 loss diverges
      "update_network_frequency": 10 # 100
      "num_real_steps": 10


  "q_model":
    "class": "FeedForwardQModel"
    "params":
      "layers": [10]
  "planning_init_replay_buffer_max_length": 1
  "fake_steps_replay_buffer_max_length": 5
  "stop_mean_return": [5,200]
  "nb_runs": 1
  "use_tf_agent": False # False
  "eps_start": 0.5 # 0.5 1.0
  "minibatch_size": 64
  "num_eval_episodes": 1
  # INTERVALS #
  "log_target_model_performance_interval": 2
  "training_interval": 1
  "update_accuracy_interval": 1
  "check_stop_transfer_interval": 1
  "update_model_interval": 2
  "use_true_done_to_stop_prediction": True
  "replay_buffer_max_length": 100000
  "planning_replay_buffer_max_length": 10 # 100000
  "shape": [1,5]
  "action_selection_for_model_prediction": "greedy" #"random" #"greedy" # "random" # greedy

  "target_gan_config":
    "D_n_updates": 1
    "G_n_updates": 1
    "D_optimizer":
      "type": "adam"
      "params":
        "learning_rate": 0.0002 #2e-4
        "beta_1": 0.5
    "G_optimizer":
      "type": "adam"
      "params":
        "learning_rate": 0.0002 #2e-4
        "beta_1": 0.5
    "use_bce_tf_function": False
    "type": "classic" # "wasserstein"
    "z_size": 1 #5
    "D_hidden_layers": [ 10]
    "G_hidden_layers": [ 10]
    "D_activation": "tanh"
    "G_activation": "tanh"

"cross_comparaison":
  "nb_samples": 2000
  "nb_episodes": 100

"create_datasets":
  "n_episodes": 10

"learn_gans":

  "baselines":
    "one_gan_by_env":
      "type": "classic"
      "D_hidden_layers": [ 10]
      "G_hidden_layers": [ 10 ]
      "learn_targets": True

    "hello_agglo_gan":
      "type": "agglomerated_gan"
      "D_hidden_layers": [ 10]
      "G_hidden_layers": [ 10 ]

    "hello_super_gan":
      "type": "super_gan"
      "D_hidden_layers": [ 10]
      "G_hidden_layers": [ 10]

  #    "one_gan_by_env_negative_sample":
  #      "type": "classic"
  #      "D_hidden_layers": [ 10]
  #      "G_hidden_layers": [ 10]
  #      "negative_sampling":
  #        "minibatch_size": 5

  "buffer_size_by_source_env": 5
  "batch_size": "max"
  "lambda_penalize_high_entropy": null #0.
  "sum_fake_and_real_for_entropy": null
  "stop":
    "max_epochs": 30 #1500
    "testing_loss_treshold": 0.005
  "lambda_": 0

  "D_n_updates": 1
  "G_n_updates": 1
  "D_optimizer":
    "type": "adam"
    "params":
      "learning_rate": 0.0002 #2e-4
      "beta_1": 0.5

  "G_optimizer":
    "type": "adam"
    "params":
      "learning_rate": 0.0002 #2e-4
      "beta_1": 0.5

  "use_bce_tf_function": False
  "factorize_fake_output": True
  "z_size": 1 #5
  "D_activation": "tanh"
  "G_activation": "tanh"


