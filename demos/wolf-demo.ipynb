{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the different ways in which the wolf library can be used. \n",
    "\n",
    "The first section covers running DQN experiments using wolf with your own config, while the second section covers how to use existing config.\n",
    "\n",
    "Third section covers using wolf for real-world networks and the final section covers QMIX training over environments created by wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Running wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different ways of using wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating a Config and Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/parth/miniconda3/envs/traffic2/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.tune import tune\n",
    "from ray import rllib\n",
    "import yaml\n",
    "import wolf\n",
    "from wolf.utils.configuration.configuration import Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell creates a config for running on simple single intersection environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(\"\"\"\n",
    "\"ray\":\n",
    "  \"init\":\n",
    "    \"local_mode\": false\n",
    "    \"log_to_driver\": true\n",
    "    \"logging_level\": \"WARNING\"\n",
    "  \"run_experiments\":\n",
    "    \"experiments\":\n",
    "      \"global_agent\":\n",
    "        \"run\": \"APEX\"\n",
    "        \"checkpoint_freq\": 1\n",
    "        \"checkpoint_at_end\": true\n",
    "        \"stop\":\n",
    "          \"training_iteration\": 100\n",
    "        \"config\":\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # OTHERS\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          # \"framework\": \"tf\"\n",
    "          \"log_level\": \"WARNING\"\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # RL ALGO PARAMS\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          \"num_gpus\": 1\n",
    "          \"num_workers\": 2\n",
    "          \"target_network_update_freq\": 100\n",
    "          \"learning_starts\": 0\n",
    "          \"timesteps_per_iteration\": 1000\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # EVALUATION\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          # \"evaluation_interval\": 10 # Evaluate with every `evaluation_interval` training iterations.\n",
    "          # \"evaluation_num_episodes\": 10\n",
    "          # \"in_evaluation\": False\n",
    "          # \"evaluation_config\":\n",
    "          #   \"explore\": False\n",
    "          # \"evaluation_num_workers\": 0\n",
    "          # \"custom_eval_function\": null\n",
    "          # \"use_exec_api\": False\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # EXPLORATION\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          # \"exploration_config\":\n",
    "          #   \"type\": \"EpsilonGreedy\"\n",
    "          #   \"epsilon_schedule\":\n",
    "          #     \"type\": \"ExponentialSchedule\" # check vizu_exp_schedule.py to find the right params for this exploration\n",
    "          #     \"schedule_timesteps\": 10000\n",
    "          #     \"initial_p\": 1.0\n",
    "          #     \"decay_rate\": 0.01\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # MODEL\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          \"model\":\n",
    "            \"custom_model\": \"tdtse\"\n",
    "            \"custom_model_config\":\n",
    "              \"filters_size\": 32\n",
    "              \"dense_layer_size_by_node\": 64 # size by node\n",
    "              \"use_progression\": false\n",
    "\n",
    "          ####################\n",
    "          ####################\n",
    "          # ENV\n",
    "          ####################\n",
    "          ####################\n",
    "\n",
    "          \"gamma\": 0.99 # 0.995\n",
    "          \"horizon\": null # if null, horizon will be choosen by env\n",
    "          \"env\": \"traffic_env_test0\"\n",
    "          \"env_config\":\n",
    "            \"render\": False\n",
    "            \"simulator\": \"traci\"\n",
    "            \"sim_params\":\n",
    "              \"restart_instance\": True\n",
    "              \"sim_step\": 1\n",
    "              \"print_warnings\": False\n",
    "              \"render\": False\n",
    "            \"env_state_params\": null\n",
    "            \"group_agents_params\": null\n",
    "            \"multi_agent_config_params\":\n",
    "              \"name\": \"shared_policy\"\n",
    "              \"params\": {}\n",
    "            \"agents_params\":\n",
    "              \"name\": \"global_agent\"\n",
    "              \"params\":\n",
    "                \"default_policy\": null\n",
    "                \"global_reward\": false\n",
    "                \"action_params\":\n",
    "                  \"name\": \"ExtendChangePhaseConnector\"\n",
    "                  \"params\": {}\n",
    "                \"obs_params\":\n",
    "                  \"name\": \"TDTSEConnector\"\n",
    "                  \"params\":\n",
    "                    \"obs_params\":\n",
    "                      \"num_history\": 60 # same results with  tbh :O 30\n",
    "                      \"detector_position\": [5, 100]\n",
    "                    \"phase_channel\": true\n",
    "                \"reward_params\":\n",
    "                  \"name\": \"QueueRewardConnector\"\n",
    "                  \"params\":\n",
    "                    \"stop_speed\": 2\n",
    "\"general\":\n",
    "  \"id\": \"main\"\n",
    "  \"seed\": null\n",
    "  \"repeat\": 1\n",
    "  \"is_tensorboardX\": false\n",
    "  \"sumo_home\": \"/home/ncarrara/sumo_binaries/bin\"\n",
    "  \"workspace\": \"test0/results\"\n",
    "  \"logging\":\n",
    "    \"version\": 1\n",
    "    \"disable_existing_loggers\": false\n",
    "    \"formatters\":\n",
    "      \"standard\":\n",
    "        \"format\": \"[%(name)s] %(levelname)s - %(message)s\"\n",
    "    \"handlers\":\n",
    "      \"default\":\n",
    "        \"level\": \"WARNING\"\n",
    "        \"formatter\": \"standard\"\n",
    "        \"class\": \"logging.StreamHandler\"\n",
    "    \"loggers\":\n",
    "      \"\":\n",
    "        \"handlers\": [\"default\"]\n",
    "        \"level\": \"WARNING\"\n",
    "        \"propagate\": false\n",
    "      \"some.logger.you.want.to.enable.in.the.code\":\n",
    "        \"handlers\": [\"default\"]\n",
    "        \"level\": \"ERROR\"\n",
    "        \"propagate\": false\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell uses above config dict to create a wolf configuration object as well load custom utilities needed to run training over this traffic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Configuration() \\\n",
    "    .load(config) \\\n",
    "    .load_custom_trainable().load_sumo() \\\n",
    "    .load_custom_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.42.11',\n",
       " 'raylet_ip_address': '192.168.42.11',\n",
       " 'redis_address': '192.168.42.11:42388',\n",
       " 'object_store_address': '/tmp/ray/session_2020-08-05_10-42-13_979455_25687/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-08-05_10-42-13_979455_25687/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-08-05_10-42-13_979455_25687'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize ray\n",
    "ray.init(**C.ray().init())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following two cells, create a params object that is required by tune to start the DQN training over the provided traffic network environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_episode_step(info):\n",
    "    episode = info[\"episode\"]\n",
    "    pass\n",
    "\n",
    "\n",
    "def setup_run_exp_params(C):\n",
    "    from ray.rllib.env.group_agents_wrapper import _GroupAgentsWrapper\n",
    "\n",
    "    from wolf.scripts.misc.vizu_exp_schedule import show_schedule\n",
    "    def resolve_multi_agent_config(spec):\n",
    "        if \"exploration_config\" in spec[\"config\"]:\n",
    "            if \"epsilon_schedule\" in spec[\"config\"][\"exploration_config\"]:\n",
    "                show_schedule(spec[\"config\"][\"exploration_config\"][\"epsilon_schedule\"])\n",
    "        from wolf.utils.configuration.registry import R\n",
    "        config = spec[\"config\"]\n",
    "        create_env = R.env_factory(config[\"env\"])\n",
    "        env = create_env(config[\"env_config\"])\n",
    "        if isinstance(env, _GroupAgentsWrapper):\n",
    "            return env.env.multi_agent_config\n",
    "        else:\n",
    "            return env.multi_agent_config\n",
    "\n",
    "    # setup config\n",
    "    run_ex_params = C.ray()[\"run_experiments\"]\n",
    "    for name, exp in run_ex_params[\"experiments\"].items():\n",
    "        config = exp[\"config\"]\n",
    "        config[\"multiagent\"] = ray.tune.sample.sample_from(lambda spec: resolve_multi_agent_config(spec))\n",
    "        config[\"callbacks\"] = {\n",
    "            \"on_episode_step\": on_episode_step,\n",
    "        }\n",
    "        exp[\"local_dir\"] = C[\"general\"][\"workspace\"]\n",
    "\n",
    "        def trial_name_string(trial):\n",
    "            name = \"{}_{}\".format(trial.trainable_name, trial.trial_id)\n",
    "            return name\n",
    "\n",
    "        exp[\"trial_name_creator\"] = trial_name_string\n",
    "\n",
    "    pprint.pprint(run_ex_params, depth=4)\n",
    "    return run_ex_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiments': {'global_agent': {'checkpoint_at_end': True,\n",
      "                                  'checkpoint_freq': 1,\n",
      "                                  'config': {'callbacks': {...},\n",
      "                                             'env': 'traffic_env_test0',\n",
      "                                             'env_config': {...},\n",
      "                                             'gamma': 0.99,\n",
      "                                             'horizon': None,\n",
      "                                             'learning_starts': 0,\n",
      "                                             'log_level': 'WARNING',\n",
      "                                             'model': {...},\n",
      "                                             'multiagent': tune.sample_from(<function setup_run_exp_params.<locals>.<lambda> at 0x7fd3884b4ea0>),\n",
      "                                             'num_gpus': 1,\n",
      "                                             'num_workers': 2,\n",
      "                                             'target_network_update_freq': 100,\n",
      "                                             'timesteps_per_iteration': 1000},\n",
      "                                  'local_dir': 'test0/results',\n",
      "                                  'run': 'APEX',\n",
      "                                  'stop': {'training_iteration': 100},\n",
      "                                  'trial_name_creator': <function setup_run_exp_params.<locals>.trial_name_string at 0x7fd38c4edd90>}}}\n"
     ]
    }
   ],
   "source": [
    "params = setup_run_exp_params(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training using tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = tune.run_experiments(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutdown ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Running using Existing Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be executed from the command line or terminal using the below commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cd sow45_code\n",
    "python wolf/scripts/main.py <path_to_config>```\n",
    "\n",
    "For example:\n",
    "\n",
    "```python wolf/scripts/main.py wolf/tests/traffic_env/test0/global_agent.yaml```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/parth/repos/traffic-management/sow45_code/demos'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/parth/repos/traffic-management/sow45_code'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change directory to sow45_code\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wolf/scripts/main.py wolf/tests/traffic_env/test0/global_agent.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Running on Real-World Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of networks. \n",
    "- Artifical Generated Networks:\n",
    "Created Programmatically.\n",
    "\n",
    "- Real-world Networks:\n",
    "Created by importing sumo.cfg and sumo configuration files (.xml) files.\n",
    "\n",
    "In this section we would see what changes are to made to the configuration file to run a real-world network training on wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Change `env` property:**\n",
    "\n",
    "`\"env\": \"<registered_env_name>\"` such as `\"env\": \"traffic_env_test0\"` changes to\n",
    "\n",
    "`\"env\": \"real_world_network\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Change `name` property inside `multi_agent_config_params` property:**\n",
    "\n",
    "Change it from:\n",
    "\n",
    "`\"multi_agent_config_params\":\n",
    "  \"name\": \"shared_policy\"` to\n",
    "\n",
    "`\"multi_agent_config_params\":\n",
    "  \"name\": \"independent_policy\"`\n",
    "  \n",
    "Shared Policy is used when intersections are exactly the same, so parameter sharing can happen between these agent networks.\n",
    "\n",
    "But for real-world networks, this is almost never the case, as all intersections have some form of dissimilarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Add the following properties to `env_config` property:**\n",
    "\n",
    "`\"net_params\":\n",
    "  \"template\":\n",
    "    \"net\": \"<path_to_network_file>.net.xml\"\n",
    "    \"rou\": \"<path_to_routes_file>.rou.xml\"\n",
    "    \"vtype\": \"<path_to_vehicle_types_or_routes_file>.rou.xml\"\n",
    "    \"add\": \"<path_to_detectors_file>.xml\"\n",
    "  \"controlled_tls\" : <list_of_intersection_ids_that_are_to_be_controlled>`\n",
    "\n",
    "For example for the case of china5ups, following is added:\n",
    "\n",
    "`\"net_params\":\n",
    "  \"template\":\n",
    "    \"net\": \"wolf/sumo_net/wujiang/china_net_5p_ups_LD_noUturn.net.xml\"\n",
    "    \"rou\": \"wolf/sumo_net/wujiang/china_flows_1hr45min_noUturn_ups.rou.xml\"\n",
    "    \"vtype\": \"wolf/sumo_net/wujiang/china_flows_1hr45min_noUturn_ups.rou.xml\"\n",
    "    \"add\": \"wolf/sumo_net/wujiang/china_net_5p_ups_loop_detectors.xml\"\n",
    "  \"controlled_tls\" : ['main_center']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Change detector configuration property in `agents_params.params.obs_params.params.obs_params`:**\n",
    "    \n",
    "For artificial network detector position is specified using following:\n",
    "    \n",
    "`\"detector_position\": [5, 295]`\n",
    "\n",
    "where these numbers represent the distance of loop detectors from the stop line.\n",
    "\n",
    "For real-world networks detector position is specified using:\n",
    "\n",
    "`\"num_detector_group\": 2`\n",
    "\n",
    "where the number denotes the number of detector groups. All other detector information is passed using the `add` file specified in the previous point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more visit the following configs at location `wolf/tests/traffic_env/`:\n",
    "\n",
    "`test4_1`, `test4_2`: These are configs that work with china5ups network.\n",
    "\n",
    "Each of these folders have different configuration of different agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Running using QMIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QMIX running commands will be different because it has not been completely integrated within the `wolf` framework. This is also the reason why it exists in a separate folder currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/parth/repos/traffic-management/sow45_code/demos'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/parth/repos/traffic-management/sow45_code'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python qmix/src/main.py --config=qmix_traf --env-config=traf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the configuration has been broken into configuration for the algorithm (`--config`) and configuration for the environment (`--env-config`).\n",
    "\n",
    "Within `--env-config` we specify `traf` which makes the program read the `traf.yaml` inside the `qmix/src/config/envs/` directory.\n",
    "\n",
    "From this file one can change the:\n",
    "- `test_env` to change between different wolf registered environments.\n",
    "- `render` to render the simulation or not.\n",
    "\n",
    "And other environment specific configuration properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
